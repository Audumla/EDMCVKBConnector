{
  "_comment": "Changelog/release summarization runtime settings. Add new backend sections alongside codex/claude_cli/intelligent as needed.",
  "changelog_summarization": {
    "_comment": "Used by scripts/summarize_changelog.py and scripts/generate_release_notes.py",
    "enabled": true,
    "backend": "codex",
    "common": {
      "_comment": "Shared settings for all backends. timeout_seconds is global fallback.",
      "timeout_seconds": 300,
      "fallback_order": ["claude-cli", "codex", "gemini", "copilot", "lmstudio"],
      "_comment_timeout_seconds": "Single command timeout in seconds for backend CLI calls (default recommendation: 300-600).",
      "changelog_prompt_requirements": [
        "1-2 sentence overview of release focus",
        "Group by: ### Bug Fixes, ### New Features, ### Improvements",
        "Use plain English bullet points",
        "Omit technical jargon, internal IDs, and slugs",
        "Markdown sections only (no conversational filler)"
      ],
      "_comment_changelog_prompt_requirements": "Instruction bullets for changelog summary prompts.",
      "release_notes_prompt_requirements": [
        "Group by: Bug Fixes, New Features, Improvements",
        "Plain English only",
        "Omit internal IDs and slugs",
        "Markdown content only (no conversational filler)"
      ],
      "_comment_release_notes_prompt_requirements": "Instruction bullets for release-note generation prompts."
    },
    "codex": {
      "_comment": "Codex backend settings (backend=codex).",
      "_comment_model": "Any model accepted by your codex CLI (examples: gpt-5, gpt-5-mini, gpt-5-codex).",
      "model": "gpt-5.3"
    },
    "claude_cli": {
      "_comment": "Claude CLI backend settings (backend=claude-cli).",
      "_comment_model": "Optional Claude model alias/name passed as --model (examples: sonnet, opus, claude-sonnet-4-6).",
      "model": "claude-3-haiku-20240307"
    },
    "copilot": {
      "_comment": "GitHub Copilot CLI backend settings (backend=copilot). Requires: Copilot CLI Windows app.",
      "_comment_install": "Install from: https://docs.github.com/en/copilot/how-tos/copilot-cli/set-up-copilot-cli/install-copilot-cli",
      "_comment_model": "Model name passed to copilot CLI. gpt-4.1 is included (no token cost).",
      "model": "gpt-4.1"
    },
    "gemini": {
      "_comment": "Google Gemini CLI backend settings (backend=gemini). Requires: Gemini CLI installed and authenticated.",
      "_comment_install": "Install from: https://github.com/google-gemini/cli or run: npm install -g @google-gemini/cli",
      "_comment_model": "Optional model name (e.g., gemini-2.0-flash, gemini-1.5-pro). Defaults to Gemini's selected model.",
      "model": ""
    },
    "lmstudio": {
      "_comment": "LMStudio local backend settings (backend=lmstudio).",
      "_comment_url": "The local server URL (usually http://localhost:1234/v1).",
      "base_url": "http://localhost:1234/v1",
      "_comment_model": "The model identifier string used by LMStudio. - qwen/qwen3-coder-30b",
      "model": "qwen/qwen3-coder-next"
    },
    "intelligent": {
      "_comment": "Deterministic local summarizer (no LLM/API usage)."
    },
    "_comment_backend": "Backend options: codex | claude-cli | copilot | gemini | intelligent"
  }
}
